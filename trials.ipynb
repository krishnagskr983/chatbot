{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import Pinecone as PineconeVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 5860\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Step 1: Load and preprocess PDF data\n",
    "def load_pdf(data_path):\n",
    "    loader = DirectoryLoader(data_path, glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "extracted_data = load_pdf(\"data/\")\n",
    "\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks\n",
    "\n",
    "text_chunks = text_split(extracted_data)\n",
    "print(\"Number of chunks:\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Initialize embeddings\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings\n",
    "\n",
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'chatbot' already exists.\n",
      "Connected to index 'chatbot'.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Configure Pinecone\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_ENV = os.getenv(\"PINECONE_ENV\")\n",
    "INDEX_NAME = os.getenv(\"INDEX_NAME\")\n",
    "DIMENSION = int(os.getenv(\"DIMENSION\"))\n",
    "\n",
    "# Initialize Pinecone client\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Check if the index exists and create it only if it doesn't\n",
    "existing_indexes = [index.name for index in pc.list_indexes()]\n",
    "if INDEX_NAME not in existing_indexes:\n",
    "    print(f\"Index '{INDEX_NAME}' does not exist. Creating index...\")\n",
    "    pc.create_index(\n",
    "        name=INDEX_NAME,\n",
    "        dimension=DIMENSION,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=PINECONE_ENV\n",
    "        )\n",
    "    )\n",
    "    print(f\"Index '{INDEX_NAME}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Index '{INDEX_NAME}' already exists.\")\n",
    "\n",
    "# Connect to the existing or newly created index\n",
    "index = pc.Index(INDEX_NAME)\n",
    "print(f\"Connected to index '{INDEX_NAME}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert complete.\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Upsert data into Pinecone\n",
    "def upsert_embeddings_to_pinecone(index, text_chunks, embeddings, batch_size=100):\n",
    "  # Extract text content from each chunk\n",
    "  chunk_texts = [t.page_content for t in text_chunks]  # t.page_content is the raw document text\n",
    "  chunk_embeddings = embeddings.embed_documents(chunk_texts)  # Generate embeddings for the text chunks\n",
    "\n",
    "  for i in range(0, len(chunk_embeddings), batch_size):\n",
    "    batch = chunk_embeddings[i:i+batch_size]  # Create a batch of embeddings\n",
    "    # Store the text content in the metadata under the 'text' key\n",
    "    metadata = [{\"text\": chunk_texts[i+j]} for j in range(len(batch))]\n",
    "    # Upsert the vectors along with their metadata (including text)\n",
    "    vectors = [(f\"id-{i+j}\", batch[j], metadata[j]) for j in range(len(batch))]\n",
    "    index.upsert(vectors)  # Upsert the vectors into Pinecone\n",
    "\n",
    "  print(\"Upsert complete.\")\n",
    "\n",
    "upsert_embeddings_to_pinecone(index, text_chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Define Pinecone as the Retriever with top k=1\n",
    "retriever = PineconeVectorStore.from_existing_index(\n",
    "    index_name=INDEX_NAME,\n",
    "    embedding=embeddings \n",
    ").as_retriever(search_kwargs={\"k\": 1}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Define Prompt Template\n",
    "prompt_template = \"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\"\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Initialize LLM\n",
    "llm = CTransformers(\n",
    "    model=\"model/llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
    "    model_type=\"llama\",\n",
    "    config={'max_new_tokens': 512, 'temperature': 0.8}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Use the Retriever in the RetrievalQA Chain\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever, \n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs=chain_type_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Acne is a common skin condition that occurs when the pores on the skin become clogged with dead skin cells, oil, and bacteria. It can cause whiteheads, blackheads, and inflamed red pimples on the face, as well as other areas of the body. Acne is most commonly seen in people during puberty, but it can also occur at any age. There are several treatment options available, including topical creams and gels, oral antibiotics, and blue light therapy.\n",
      "Response: Allergies occur when your immune system mistakenly identifies a harmless substance, such as pollen, dust, or food, as a threat. When this substance enters your body, your immune system produces antibodies to fight it off, leading to an inflammatory response and the symptoms associated with allergies.\n",
      "Exiting the program. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Query Loop with Top k = 1 response\n",
    "while True:\n",
    "    user_input = input(\"Enter your question (or type 'exit' to quit): \")\n",
    "    if user_input.lower() == \"exit\": \n",
    "        print(\"Exiting the program. Goodbye!\")\n",
    "        break \n",
    "    \n",
    "    result = qa.invoke({\"query\": user_input})  \n",
    "    print(\"Response:\", result[\"result\"]) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

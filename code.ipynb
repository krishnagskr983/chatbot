{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from pinecone import Pinecone, ServerlessSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 5860\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Step 1: Load and preprocess PDF data\n",
    "def load_pdf(data_path):\n",
    "    loader = DirectoryLoader(data_path, glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "extracted_data = load_pdf(\"data/\")\n",
    "\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks\n",
    "\n",
    "text_chunks = text_split(extracted_data)\n",
    "print(\"Number of chunks:\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Initialize embeddings\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings\n",
    "\n",
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'chatbot' already exists.\n",
      "Connected to index 'chatbot'.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Configure Pinecone\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "INDEX_NAME = os.getenv(\"INDEX_NAME\")\n",
    "DIMENSION = int(os.getenv(\"DIMENSION\"))\n",
    "\n",
    "# Initialize Pinecone client\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Check if the index exists and create it only if it doesn't\n",
    "try:\n",
    "  existing_indexes = [index.name for index in pc.list_indexes()]\n",
    "  if INDEX_NAME in existing_indexes:\n",
    "    print(f\"Index '{INDEX_NAME}' already exists.\")\n",
    "  else:\n",
    "    print(f\"Index '{INDEX_NAME}' does not exist. Creating index...\")\n",
    "    pc.create_index(\n",
    "      name=INDEX_NAME,\n",
    "      dimension=DIMENSION,\n",
    "      metric=\"cosine\",\n",
    "      spec=ServerlessSpec(\n",
    "          cloud=\"aws\",\n",
    "          region=\"us-east-1\"\n",
    "      )\n",
    "    )\n",
    "    print(f\"Index '{INDEX_NAME}' created successfully.\")\n",
    "except Exception as e:\n",
    "  print(f\"Error during index management: {e}\")\n",
    "\n",
    "# Connect to the existing or newly created index\n",
    "try:\n",
    "  index = pc.Index(INDEX_NAME)\n",
    "  print(f\"Connected to index '{INDEX_NAME}'.\")\n",
    "except Exception as e:\n",
    "  print(f\"Error connecting to index '{INDEX_NAME}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert complete.\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Upsert data into Pinecone\n",
    "def upsert_embeddings_to_pinecone(index, text_chunks, embeddings, batch_size=100):\n",
    "    chunk_texts = [t.page_content for t in text_chunks]\n",
    "    chunk_embeddings = embeddings.embed_documents(chunk_texts)\n",
    "\n",
    "    for i in range(0, len(chunk_embeddings), batch_size):\n",
    "        batch = chunk_embeddings[i:i+batch_size]\n",
    "        metadata = [{\"page_content\": chunk_texts[i+j]} for j in range(len(batch))]\n",
    "        vectors = [(f\"id-{i+j}\", batch[j], metadata[j]) for j in range(len(batch))]\n",
    "        index.upsert(vectors)\n",
    "\n",
    "    print(\"Upsert complete.\")\n",
    "\n",
    "upsert_embeddings_to_pinecone(index, text_chunks, embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

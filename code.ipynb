{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import Pinecone as PineconeVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 5860\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Step 1: Load and preprocess PDF data\n",
    "def load_pdf(data_path):\n",
    "    loader = DirectoryLoader(data_path, glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "extracted_data = load_pdf(\"data/\")\n",
    "\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks\n",
    "\n",
    "text_chunks = text_split(extracted_data)\n",
    "print(\"Number of chunks:\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Initialize embeddings\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings\n",
    "\n",
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'chatbot' already exists.\n",
      "Connected to index 'chatbot'.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Configure Pinecone\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_ENV = os.getenv(\"PINECONE_ENV\")\n",
    "INDEX_NAME = os.getenv(\"INDEX_NAME\")\n",
    "DIMENSION = int(os.getenv(\"DIMENSION\"))\n",
    "\n",
    "# Initialize Pinecone client\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Check if the index exists and create it only if it doesn't\n",
    "existing_indexes = [index.name for index in pc.list_indexes()]\n",
    "if INDEX_NAME not in existing_indexes:\n",
    "    print(f\"Index '{INDEX_NAME}' does not exist. Creating index...\")\n",
    "    pc.create_index(\n",
    "        name=INDEX_NAME,\n",
    "        dimension=DIMENSION,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=PINECONE_ENV\n",
    "        )\n",
    "    )\n",
    "    print(f\"Index '{INDEX_NAME}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Index '{INDEX_NAME}' already exists.\")\n",
    "\n",
    "# Connect to the existing or newly created index\n",
    "index = pc.Index(INDEX_NAME)\n",
    "print(f\"Connected to index '{INDEX_NAME}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsert complete.\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Upsert data into Pinecone\n",
    "def upsert_embeddings_to_pinecone(index, text_chunks, embeddings, batch_size=100):\n",
    "    chunk_texts = [t.page_content for t in text_chunks]\n",
    "    chunk_embeddings = embeddings.embed_documents(chunk_texts)\n",
    "\n",
    "    for i in range(0, len(chunk_embeddings), batch_size):\n",
    "        batch = chunk_embeddings[i:i+batch_size]\n",
    "        metadata = [{\"page_content\": chunk_texts[i+j]} for j in range(len(batch))]\n",
    "        vectors = [(f\"id-{i+j}\", batch[j], metadata[j]) for j in range(len(batch))]\n",
    "        index.upsert(vectors)\n",
    "\n",
    "    print(\"Upsert complete.\")\n",
    "\n",
    "upsert_embeddings_to_pinecone(index, text_chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Define Pinecone as the Retriever with top k=1\n",
    "retriever = PineconeVectorStore.from_existing_index(\n",
    "    index_name=INDEX_NAME,\n",
    "    embedding=embeddings \n",
    ").as_retriever(search_kwargs={\"k\": 1}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Define Prompt Template\n",
    "prompt_template = \"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\"\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Initialize LLM\n",
    "llm = CTransformers(\n",
    "    model=\"model/llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
    "    model_type=\"llama\",\n",
    "    config={'max_new_tokens': 512, 'temperature': 0.8}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Use the Retriever in the RetrievalQA Chain\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever, \n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs=chain_type_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found document with no `text` key. Skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Acne is a common skin condition that occurs when the pores on the skin become clogged with oil, dead skin cells, and bacteria. It can cause redness, inflammation, and pimples on the face, as well as other areas of the body. There are several types of acne, including blackheads, whiteheads, and nodules. Acne can be caused by a variety of factors, including hormonal changes, genetics, and environmental factors such as stress and humidity. Treatment options for acne include topical creams and gels, oral antibiotics, and lifestyle changes such as regular exercise and a healthy diet.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found document with no `text` key. Skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Allergies occur when your immune system overreacts to a foreign substance, such as pollen, dust mites, or peanuts. When this substance enters your body, your immune system produces antibodies to fight it off, leading to the release of chemical mediators, such as histamine. This can cause a range of symptoms, including sneezing, runny nose, itchy eyes, and difficulty breathing. In severe cases, allergies can lead to anaphylaxis, a life-threatening reaction that requires immediate medical attention.\n",
      "\n",
      "Please let me know if you need anything else!\n",
      "Exiting the program. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Query Loop with Top k = 1 response\n",
    "while True:\n",
    "    user_input = input(\"Enter your question (or type 'exit' to quit): \")\n",
    "    if user_input.lower() == \"exit\": \n",
    "        print(\"Exiting the program. Goodbye!\")\n",
    "        break \n",
    "    result = qa({\"query\": user_input})  \n",
    "    print(\"Response:\", result[\"result\"]) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
